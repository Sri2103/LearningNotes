# Gradient Descent

θ = θ - α \* ∇L(θ)

# Softmax

softmax(z_i) = e^(z_i) / Σ e^(z_j)

# Cross-Entropy Loss

L = - Σ y \* log(p)

# Train/Val/Test Split Template

60% — 20% — 20%
